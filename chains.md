The chains are responsible for creating an end-to-end pipeline for using the language models.

They will join the model, prompt, memory, parsing output, and debugging capability and provide an easy-to-use interface.

A chain will 1) receive the user’s query as an input, 2) process the LLM’s response, and lastly, 3) return the output to the user.
